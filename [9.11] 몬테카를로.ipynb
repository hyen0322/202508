{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjNfRl5DX+IqlQLtyA9HKo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os, re, json, math, warnings, glob, shutil\n",
        "import numpy as np, pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.stats import (gumbel_r, gumbel_l, lognorm, weibull_min, logistic, t,\n",
        "                         norm, gamma, beta, triang, expon, pareto, uniform, chi2)\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
        "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "np.random.seed(20250912)\n",
        "N_SIM = 10_000\n",
        "BOOTSTRAP_B = 200\n",
        "IUR = {\"Cr(VI)\":1.20e-02,\"Co\":9.00e-03,\"Ni\":2.40e-04,\"As\":4.30e-03,\"Cd\":1.80e-03,\"Sb\":2.29e-06,\"Pb\":1.20e-05}\n",
        "ORDER = ['Cr','Cr(VI)','Co','Ni','As','Cd','Sb','Pb']\n",
        "PAT = {\n",
        "    \"Cr(VI)\": r\"(?:\\bCr\\s*\\(?VI\\)?\\b|Cr6|Hexa(?:valent)?\\s*Chrom)\",\n",
        "    \"Cr\"    : r\"(?:\\bCr\\b(?!\\s*\\(?VI\\)?))\",\n",
        "    \"Co\"    : r\"(?:\\bCo\\b|Cobalt)\",\n",
        "    \"Ni\"    : r\"(?:\\bNi\\b|Nickel)\",\n",
        "    \"As\"    : r\"(?:\\bAs\\b|Arsenic)\",\n",
        "    \"Cd\"    : r\"(?:\\bCd\\b|Cadmium)\",\n",
        "    \"Sb\"    : r\"(?:\\bSb\\b|Antimony)\",\n",
        "    \"Pb\"    : r\"(?:\\bPb\\b|Lead)\",\n",
        "}\n",
        "POS_ONLY = {'로그 정규','와이블','감마','지수','파레토'}\n",
        "\n",
        "# Excel style\n",
        "HEADER_BLUE = '2F5597'\n",
        "BEST_FILL  = 'FFF2CC'\n",
        "THIN_GRAY  = '999999'\n",
        "TABLE_STYLE = \"TableStyleMedium9\"\n",
        "\n",
        "# Exposure params\n",
        "EF_days_per_year = 350; EF = EF_days_per_year/365.0\n",
        "LT_years = 78.6\n",
        "ACT_POINT = {\"0-<1\":24,\"1-<2\":84,\"2-<3\":120,\"3-<6\":108,\"6-<11\":132,\"11-<16\":102,\"16-<18\":102}  # min/day\n",
        "ACT_LN_P5_P95 = {\"18-<25\":(14.455,250.0),\"25-<35\":(6.516,220.0),\"35-<45\":(5.789,195.0),\n",
        "                 \"45-<55\":(6.401,260.0),\"55-<65\":(8.083,350.0),\"65-<78.6\":(6.094,390.0)}\n",
        "ED_years = {\"0-<1\":1,\"1-<2\":1,\"2-<3\":1,\"3-<6\":3,\"6-<11\":5,\"11-<16\":5,\"16-<18\":2,\n",
        "            \"18-<25\":7,\"25-<35\":10,\"35-<45\":10,\"45-<55\":10,\"55-<65\":10,\"65-<78.6\":13.6}\n",
        "AGE_ORDER=[\"0-<1\",\"1-<2\",\"2-<3\",\"3-<6\",\"6-<11\",\"11-<16\",\"16-<18\",\"18-<25\",\"25-<35\",\"35-<45\",\"45-<55\",\"55-<65\",\"65-<78.6\"]\n",
        "def ADAF(lbl): a=float(lbl.split('-')[0]); return 10.0 if a<2 else (3.0 if a<16 else 1.0)\n",
        "\n",
        "# 연령 그룹(Infant/Child/Adult) 집계용\n",
        "INFANT = [\"0-<1\",\"1-<2\",\"2-<3\"]\n",
        "CHILD  = [\"3-<6\",\"6-<11\",\"11-<16\",\"16-<18\"]\n",
        "ADULT  = [\"18-<25\",\"25-<35\",\"35-<45\",\"45-<55\",\"55-<65\",\"65-<78.6\"]\n",
        "\n",
        "# RNG helper\n",
        "_master_rs = np.random.RandomState(20250912)\n",
        "def child_rs(): return np.random.RandomState(_master_rs.randint(0, 2**31-1))\n",
        "\n",
        "# 데이터 로드\n",
        "print(\"로우데이터 엑셀 업로드(.xlsx)\")\n",
        "up = files.upload()\n",
        "INPUT = next((k for k in up if k.lower().endswith(('.xlsx','.xls'))), None)\n",
        "if INPUT is None:\n",
        "    cand = sorted(glob.glob(\"*.xlsx\"))\n",
        "    if not cand: raise FileNotFoundError(\"엑셀(.xlsx/.xls) 파일을 찾지 못했습니다.\")\n",
        "    INPUT = cand[-1]\n",
        "raw = pd.read_excel(INPUT)\n",
        "\n",
        "# helpers\n",
        "def find_col(df, regex):\n",
        "    for c in df.columns:\n",
        "        if re.search(regex, str(c), flags=re.I): return c\n",
        "    return None\n",
        "\n",
        "def to_ug(series, name):\n",
        "    s = pd.to_numeric(series, errors='coerce').replace([np.inf,-np.inf], np.nan)\n",
        "    if re.search(r'(?i)\\bng\\b|ng/?m', str(name)):  # ng → µg\n",
        "        return (s/1000.0, 'converted_from_ng')\n",
        "    return (s, 'as_is_ug')\n",
        "\n",
        "def hist_mode_estimate(x):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "    if x.size<2: return float(np.nanmedian(x)) if x.size else np.nan\n",
        "    iqr=np.subtract(*np.percentile(x,[75,25]))\n",
        "    bins=max(10,int(np.sqrt(x.size))) if iqr<=0 else max(10,int(np.ceil((x.max()-x.min())/(2*iqr*x.size**(-1/3)))) )\n",
        "    cnt,edges=np.histogram(x,bins=bins); i=int(cnt.argmax())\n",
        "    return float((edges[i]+edges[i+1])/2)\n",
        "\n",
        "# preprocess: unit + trim + derive Cr(VI)\n",
        "series_map, log_rows = {}, []\n",
        "for m in ORDER:\n",
        "    c = find_col(raw, PAT.get(m, r\"$^$\"))\n",
        "    if c is None: log_rows.append((m, None, 'missing', 0, np.nan)); continue\n",
        "    v, how = to_ug(raw[c], c); series_map[m]=v\n",
        "    log_rows.append((m, c, how, int(v.notna().sum()), float(np.nanmean(v))))\n",
        "log = pd.DataFrame(log_rows, columns=['Metal','Matched_Column','Unit_Status','N_nonNa','Mean(ug/m3)'])\n",
        "\n",
        "trimmed={}; q5_map={}; q95_map={}; mode_map={}\n",
        "for m,s in series_map.items():\n",
        "    x=s.dropna(); x=x[x>0]\n",
        "    if x.size==0: continue\n",
        "    q5,q95=np.percentile(x,[5,95]); xe=x[(x>=q5)&(x<=q95)]\n",
        "    if xe.size==0: continue\n",
        "    trimmed[m]=xe\n",
        "    q5_map[m]=float(q5); q95_map[m]=float(q95); mode_map[m]=float(hist_mode_estimate(xe))\n",
        "\n",
        "# Cr(VI) 추가 (트리밍 후)\n",
        "if 'Cr' in trimmed and (('Cr(VI)' not in trimmed) or trimmed['Cr(VI)'].empty):\n",
        "    trimmed['Cr(VI)']=trimmed['Cr']/7.0\n",
        "    q5_map['Cr(VI)']=q5_map.get('Cr', np.nan)/7.0 if 'Cr' in q5_map else np.nan\n",
        "    q95_map['Cr(VI)']=q95_map.get('Cr', np.nan)/7.0 if 'Cr' in q95_map else np.nan\n",
        "    mode_map['Cr(VI)']=mode_map.get('Cr', np.nan)/7.0 if 'Cr' in mode_map else np.nan\n",
        "\n",
        "# \"로우데이터 vs 극단값 전처리\" 시트 구성 (메타 4열 + 금속 raw/pre)\n",
        "def find_first(df, pattern):\n",
        "    for c in df.columns:\n",
        "        if re.search(pattern, str(c), flags=re.I):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "col_pbeg = find_first(raw, r'pump[-_\\s]?begin|^begin\\b|start time')\n",
        "col_pend = find_first(raw, r'pump[-_\\s]?end|^end\\b|stop time')\n",
        "col_mrst = find_first(raw, r'mass\\s*reset|massresett?ime|reset\\s*time')\n",
        "col_conc = find_first(raw, r'^conc\\b.*')\n",
        "\n",
        "meta_cols = []\n",
        "if col_pbeg: meta_cols.append(raw[col_pbeg].rename('Pump-Begin'))\n",
        "if col_pend: meta_cols.append(raw[col_pend].rename('Pump-End'))\n",
        "if col_mrst: meta_cols.append(raw[col_mrst].rename('MassResetTime'))\n",
        "if col_conc:\n",
        "    name_lower = str(col_conc).lower()\n",
        "    conc_series = pd.to_numeric(raw[col_conc], errors='coerce')\n",
        "    if 'ng' in name_lower:\n",
        "        conc_series = conc_series / 1000.0  # 단위 환산만; 트리밍 없음\n",
        "    meta_cols.append(conc_series.rename('Conc(µg/m³)'))\n",
        "meta_df = pd.concat(meta_cols, axis=1) if meta_cols else pd.DataFrame()\n",
        "\n",
        "comp_cols=[]\n",
        "for m in ORDER:\n",
        "    raw_col = find_col(raw, PAT.get(m, r\"$^$\"))\n",
        "    if raw_col is None:\n",
        "        comp_cols.append(pd.Series(dtype=float, name=f\"{m} (raw, µg/m³)\"))\n",
        "        comp_cols.append(pd.Series(dtype=float, name=f\"{m} (pre, µg/m³)\"))\n",
        "        continue\n",
        "    raw_ug,_ = to_ug(raw[raw_col], raw_col)\n",
        "    pre = trimmed[m].reindex(raw.index) if m in trimmed else pd.Series(index=raw.index, dtype=float)\n",
        "    comp_cols.append(raw_ug.rename(f\"{m} (raw, µg/m³)\"))\n",
        "    comp_cols.append(pre.rename(f\"{m} (pre, µg/m³)\"))\n",
        "metals_df = pd.concat(comp_cols, axis=1)\n",
        "comp = pd.concat([meta_df, metals_df], axis=1)\n",
        "comp.columns = [str(c) for c in comp.columns]  # MultiIndex 방지\n",
        "\n",
        "os.makedirs(\"preprocessed\", exist_ok=True)\n",
        "with pd.ExcelWriter(\"preprocessed/preprocessed_data.xlsx\") as w:\n",
        "    comp.to_excel(w, sheet_name=\"원자료 vs 전처리\", index=False)\n",
        "log.to_excel(\"preprocessed/preprocess_log.xlsx\", index=False)\n",
        "\n",
        "# distribution wrappers & AD bootstrap\n",
        "class D:\n",
        "    def __init__(self,name): self.name=name; self.p={}; self.np=None; self.valid=False\n",
        "    def ok(self,p,np_): self.p=p; self.np=np_; self.valid=True; return self\n",
        "    def cdf(self,z): raise NotImplementedError\n",
        "    def ppf(self,q): raise NotImplementedError\n",
        "    def rvs(self,n,rs=None): raise NotImplementedError\n",
        "\n",
        "class LogNormal(D):\n",
        "    def __init__(self): super().__init__('로그 정규')\n",
        "    def fit(self,x):\n",
        "        x=x[x>0]\n",
        "        try: s,loc,sc=lognorm.fit(x, floc=0); assert s>0 and sc>0; return self.ok({'s':s,'scale':sc},2)\n",
        "        except: return self\n",
        "    def cdf(self,z): return lognorm.cdf(z, s=self.p['s'], loc=0, scale=self.p['scale'])\n",
        "    def ppf(self,q): return lognorm.ppf(q, s=self.p['s'], loc=0, scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return lognorm.rvs(self.p['s'], loc=0, scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class Weibull(D):\n",
        "    def __init__(self): super().__init__('와이블')\n",
        "    def fit(self,x):\n",
        "        x=x[x>0]\n",
        "        try: c,loc,sc=weibull_min.fit(x, floc=0); assert c>0 and sc>0; return self.ok({'c':c,'scale':sc},2)\n",
        "        except: return self\n",
        "    def cdf(self,z): return weibull_min.cdf(z, c=self.p['c'], loc=0, scale=self.p['scale'])\n",
        "    def ppf(self,q): return weibull_min.ppf(q, c=self.p['c'], loc=0, scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return weibull_min.rvs(self.p['c'], loc=0, scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class Gamma_(D):\n",
        "    def __init__(self): super().__init__('감마')\n",
        "    def fit(self,x):\n",
        "        x=x[x>0]\n",
        "        try: a,loc,sc=gamma.fit(x, floc=0); assert a>0 and sc>0; return self.ok({'a':a,'scale':sc},2)\n",
        "        except: return self\n",
        "    def cdf(self,z): return gamma.cdf(z, a=self.p['a'], loc=0, scale=self.p['scale'])\n",
        "    def ppf(self,q): return gamma.ppf(q, a=self.p['a'], loc=0, scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return gamma.rvs(self.p['a'], loc=0, scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class LogisticD(D):\n",
        "    def __init__(self): super().__init__('로지스틱')\n",
        "    def fit(self,x):\n",
        "        try: loc,sc=logistic.fit(x); assert sc>0; return self.ok({'loc':loc,'scale':sc},2)\n",
        "        except: return self\n",
        "    def cdf(self,z): return logistic.cdf(z, **self.p)\n",
        "    def ppf(self,q): return logistic.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return logistic.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class NormalD(D):\n",
        "    def __init__(self): super().__init__('정규')\n",
        "    def fit(self,x):\n",
        "        try: mu,sig=norm.fit(x); assert sig>0; return self.ok({'loc':mu,'scale':sig},2)\n",
        "        except: return self\n",
        "    def cdf(self,z): return norm.cdf(z, **self.p)\n",
        "    def ppf(self,q): return norm.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return norm.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class StudentT(D):\n",
        "    def __init__(self): super().__init__('스튜던트의 t')\n",
        "    def fit(self,x):\n",
        "        try: df_,loc,sc=t.fit(x); assert df_>0 and sc>0; return self.ok({'df':df_,'loc':loc,'scale':sc},3)\n",
        "        except: return self\n",
        "    def cdf(self,z): return t.cdf(z, **self.p)\n",
        "    def ppf(self,q): return t.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return t.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class Exponential_(D):\n",
        "    def __init__(self): super().__init__('지수')\n",
        "    def fit(self,x):\n",
        "        x=x[x>0]\n",
        "        try: loc,sc=expon.fit(x, floc=0); assert sc>0; return self.ok({'scale':sc},1)\n",
        "        except: return self\n",
        "    def cdf(self,z): return expon.cdf(z, loc=0, scale=self.p['scale'])\n",
        "    def ppf(self,q): return expon.ppf(q, loc=0, scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return expon.rvs(size=n, loc=0, scale=self.p['scale'], random_state=rs)\n",
        "\n",
        "class BetaPERT_(D):\n",
        "    def __init__(self,lam=4.0): super().__init__('BetaPERT'); self.lam=lam\n",
        "    def fit(self,x):\n",
        "        a,b=float(np.min(x)),float(np.max(x));\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        m=float(np.clip(hist_mode_estimate(x), a+1e-9, b-1e-9))\n",
        "        al=1+self.lam*(m-a)/(b-a); be=1+self.lam*(b-m)/(b-a)\n",
        "        if al<=0 or be<=0: return self\n",
        "        return self.ok({'a':a,'b':b,'alpha':al,'beta':be,'m':m},2)\n",
        "    def cdf(self,z): return beta.cdf((z-self.p['a'])/(self.p['b']-self.p['a']), self.p['alpha'], self.p['beta'])\n",
        "    def ppf(self,q): return self.p['a']+(self.p['b']-self.p['a'])*beta.ppf(q, self.p['alpha'], self.p['beta'])\n",
        "    def rvs(self,n,rs=None):\n",
        "        r=beta.rvs(self.p['alpha'], self.p['beta'], size=n, random_state=rs)\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*r\n",
        "\n",
        "class Triangular_(D):\n",
        "    def __init__(self): super().__init__('삼각형')\n",
        "    def fit(self,x):\n",
        "        a,b=float(np.min(x)),float(np.max(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        m=float(np.clip(hist_mode_estimate(x), a+1e-9, b-1e-9)); c=(m-a)/(b-a)\n",
        "        if not(0<c<1): return self\n",
        "        return self.ok({'a':a,'b':b,'m':m,'c':c},3)\n",
        "    def cdf(self,z): return triang.cdf(z, c=self.p['c'], loc=self.p['a'], scale=(self.p['b']-self.p['a']))\n",
        "    def ppf(self,q): return triang.ppf(q, c=self.p['c'], loc=self.p['a'], scale=(self.p['b']-self.p['a']))\n",
        "    def rvs(self,n,rs=None): return triang.rvs(self.p['c'], loc=self.p['a'], scale=(self.p['b']-self.p['a']), size=n, random_state=rs)\n",
        "\n",
        "class Uniform_(D):\n",
        "    def __init__(self): super().__init__('균일')\n",
        "    def fit(self,x):\n",
        "        a,b=float(np.min(x)),float(np.max(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        return self.ok({'loc':a,'scale':(b-a)},2)\n",
        "    def cdf(self,z): return uniform.cdf(z, **self.p)\n",
        "    def ppf(self,q): return uniform.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return uniform.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class GumbelR_(D):\n",
        "    def __init__(self): super().__init__('최대 극값')\n",
        "    def fit(self,x):\n",
        "        try: loc,sc=gumbel_r.fit(x); assert np.isfinite(loc) and sc>0; return self.ok({'loc':loc,'scale':sc},2)\n",
        "        except: return self\n",
        "    def cdf(self,z): return gumbel_r.cdf(z, **self.p)\n",
        "    def ppf(self,q): return gumbel_r.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return gumbel_r.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class GumbelL_(D):\n",
        "    def __init__(self): super().__init__('최소 극값')\n",
        "    def fit(self,x):\n",
        "        try: loc,sc=gumbel_l.fit(x); assert np.isfinite(loc) and sc>0; return self.ok({'loc':loc,'scale':sc},2)\n",
        "        except: return self\n",
        "    def cdf(self,z): return gumbel_l.cdf(z, **self.p)\n",
        "    def ppf(self,q): return gumbel_l.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return gumbel_l.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class Beta_(D):\n",
        "    def __init__(self): super().__init__('베타')\n",
        "    def fit(self,x):\n",
        "        a,b=float(np.min(x)),float(np.max(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        z=np.clip((x-a)/(b-a), 1e-9, 1-1e-9)\n",
        "        try: al,be,_,_ = beta.fit(z, floc=0, fscale=1); assert al>0 and be>0;\n",
        "        except: return self\n",
        "        return self.ok({'a':a,'b':b,'alpha':al,'beta':be},2)\n",
        "    def cdf(self,z):\n",
        "        zz=(z-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        return beta.cdf(zz, self.p['alpha'], self.p['beta'])\n",
        "    def ppf(self,q):\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*beta.ppf(q, self.p['alpha'], self.p['beta'])\n",
        "    def rvs(self,n,rs=None):\n",
        "        r=beta.rvs(self.p['alpha'], self.p['beta'], size=n, random_state=rs)\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*r\n",
        "\n",
        "class Pareto_(D):\n",
        "    def __init__(self): super().__init__('파레토')\n",
        "    def fit(self,x):\n",
        "        x=x[x>0]\n",
        "        try: b,loc,sc=pareto.fit(x, floc=0); assert b>0 and sc>0; return self.ok({'b':b,'scale':sc},2)\n",
        "        except: return self\n",
        "    def cdf(self,z): return pareto.cdf(z, b=self.p['b'], loc=0, scale=self.p['scale'])\n",
        "    def ppf(self,q): return pareto.ppf(q, b=self.p['b'], loc=0, scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return pareto.rvs(self.p['b'], loc=0, scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "def AD_stat(x, cdf, eps=1e-12):\n",
        "    x=np.sort(np.asarray(x,float)); n=x.size\n",
        "    if n<5: return np.inf\n",
        "    u=np.clip(cdf(x),eps,1-eps); i=np.arange(1,n+1)\n",
        "    return float(-n - np.sum((2*i-1)*(np.log(u)+np.log(1-u[::-1])))/n)\n",
        "\n",
        "def AD_p_boot_refit(x, dist_obj, B=BOOTSTRAP_B):\n",
        "    x=np.asarray(x,float); n=x.size\n",
        "    if n<5 or not dist_obj.valid: return np.nan\n",
        "    A2_obs=AD_stat(x, dist_obj.cdf); ge=0; m=0\n",
        "    for _ in range(B):\n",
        "        rs=child_rs(); xs=dist_obj.rvs(n, rs=rs)\n",
        "        d=type(dist_obj)(); d.fit(xs)\n",
        "        if not d.valid: continue\n",
        "        A2_bs=AD_stat(xs, d.cdf); ge+=(A2_bs>=A2_obs); m+=1\n",
        "    return float((ge+1)/(m+1)) if m>0 else np.nan\n",
        "\n",
        "def KS_stat_p(x,d):\n",
        "    try: D,p=stats.kstest(x, lambda z: d.cdf(z)); return float(D), float(p)\n",
        "    except: return np.nan,np.nan\n",
        "\n",
        "def Chi2_stat_p(x,d):\n",
        "    try:\n",
        "        n=len(x); N=max(5,min(50,n//5)); eps=1e-6\n",
        "        qs=np.linspace(eps,1-eps,N+1); edges=np.unique(d.ppf(qs))\n",
        "        if len(edges)<3: return np.nan,np.nan\n",
        "        obs,_=np.histogram(x,bins=edges); exp=np.diff(qs)*n\n",
        "        k=d.np or 0; df=len(obs)-1-k\n",
        "        if df<=0: return np.nan,np.nan\n",
        "        exp=np.maximum(exp[:len(obs)],1e-9)\n",
        "        chi=np.sum((obs-exp)**2/exp); p=1.0-chi2.cdf(chi,df)\n",
        "        return float(chi), float(p)\n",
        "    except: return np.nan,np.nan\n",
        "\n",
        "def pstr(name,p):\n",
        "    try:\n",
        "        if name=='로그 정규': return f\"형태={p['s']:.5g}, 스케일={p['scale']:.5g}, 위치=0\"\n",
        "        if name=='와이블':   return f\"형태={p['c']:.5g}, 스케일={p['scale']:.5g}, 위치=0\"\n",
        "        if name=='감마':     return f\"형태={p['a']:.5g}, 스케일={p['scale']:.5g}, 위치=0\"\n",
        "        if name=='지수':     return f\"비율={1.0/p['scale']:.5g}\"\n",
        "        if name in ['최대 극값','최소 극값','정규','로지스틱']:\n",
        "            lab='최고가능성' if '극값' in name else '평균'\n",
        "            return f\"{lab}={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='스튜던트의 t': return f\"중간점={p['loc']:.5g}, 스케일={p['scale']:.5g}, 자유도={p['df']:.5g}\"\n",
        "        if name=='베타':     return f\"최소={p.get('a','?'):.5g}, 최대={p.get('b','?'):.5g}, 알파={p.get('alpha','?'):.5g}, 베타={p.get('beta','?'):.5g}\"\n",
        "        if name=='BetaPERT': return f\"최소={p['a']:.5g}, 최고가능성={p['m']:.5g}, 최대={p['b']:.5g}, α={p['alpha']:.5g}, β={p['beta']:.5g}\"\n",
        "        if name=='삼각형':   return f\"최소={p['a']:.5g}, 최고가능성={p['m']:.5g}, 최대={p['b']:.5g}\"\n",
        "        if name=='균일':     return f\"최소={p['loc']:.5g}, 최대={(p['loc']+p['scale']):.5g}\"\n",
        "        if name=='파레토':   return f\"위치=0, 스케일={p['scale']:.5g}, 형태={p['b']:.5g}\"\n",
        "        return json.dumps(p, ensure_ascii=False)\n",
        "    except Exception:\n",
        "        return json.dumps(p, ensure_ascii=False)\n",
        "\n",
        "def fit_one(x):\n",
        "    x=pd.Series(x, dtype=float).replace([np.inf,-np.inf], np.nan).dropna().values\n",
        "    if x.size<20: return None\n",
        "    cands=[LogNormal(),Gamma_(),Weibull(),LogisticD(),NormalD(),StudentT(),\n",
        "           Exponential_(),BetaPERT_(),Triangular_(),Uniform_(),GumbelR_(),GumbelL_(),\n",
        "           Beta_(), Pareto_()]\n",
        "    rows=[]\n",
        "    for d in cands:\n",
        "        d.fit(x)\n",
        "        if not d.valid:\n",
        "            rows.append({'분포':d.name,'AD':np.inf,'ADp':np.nan,'KSp':-np.inf,'Chi2p':-np.inf,'np':1e9,'obj':d})\n",
        "            continue\n",
        "        xe = x[x>0] if d.name in POS_ONLY else x\n",
        "        A2=AD_stat(xe, d.cdf); pAD=AD_p_boot_refit(xe, d, BOOTSTRAP_B)\n",
        "        D,p=KS_stat_p(xe,d); chi,pc=Chi2_stat_p(xe,d)\n",
        "        rows.append({'분포':d.name,'AD':A2,'ADp':pAD,'KSp':p,'Chi2p':pc,'np':d.np or 9,'obj':d})\n",
        "    df=pd.DataFrame(rows)\n",
        "    df['_key']=list(zip(df['AD'].fillna(np.inf), (-df['KSp']).fillna(np.inf), (-df['Chi2p']).fillna(np.inf), df['np'].fillna(np.inf)))\n",
        "    df=df.sort_values('_key', kind='mergesort').drop(columns=['_key']).reset_index(drop=True)\n",
        "    best=df.iloc[0]\n",
        "    return best, df\n",
        "\n",
        "# 피팅\n",
        "fit_tables={}\n",
        "for m in ORDER:\n",
        "    if m not in trimmed or trimmed[m].size==0:\n",
        "        fit_tables[m]={'best':None,'table':pd.DataFrame()}\n",
        "        continue\n",
        "    if m=='Cr(VI)':  # 표는 Cr과 동일(검정/분포 이름 그대로 복사)\n",
        "        fit_tables[m]={'best':None,'table':pd.DataFrame()}  # 표 자체는 비워두고 Tx-일괄에서 Cr 참조\n",
        "        continue\n",
        "    res=fit_one(trimmed[m].values)\n",
        "    if res is None:\n",
        "        fit_tables[m]={'best':None,'table':pd.DataFrame()}\n",
        "    else:\n",
        "        best, df = res\n",
        "        fit_tables[m]={'best':best,'table':df}\n",
        "\n",
        "# K_total (Infant/Child/Adult/Lifetime)\n",
        "_Z95=1.6448536269514722\n",
        "def mu_sigma_from_p5p95(p5,p95):\n",
        "    p5=max(1e-9,float(p5)); p95=max(1e-9,float(p95))\n",
        "    if p95<=p5: p95=p5*1.01\n",
        "    ln5,ln95=np.log(p5),np.log(p95); sigma=(ln95-ln5)/(2*_Z95); mu=(ln5+ln95)/2; return mu,sigma\n",
        "def sample_AcTout(age, n):\n",
        "    if age in ACT_POINT: return np.full(n, float(ACT_POINT[age]), dtype=float)   # min/day\n",
        "    p5,p95=ACT_LN_P5_P95[age]; mu,sg=mu_sigma_from_p5p95(p5,p95)\n",
        "    return np.random.lognormal(mu,sg,size=n)                                      # min/day\n",
        "\n",
        "def K_by_group(n):\n",
        "    # 그룹별 K (Infant/Child/Adult)과 Total\n",
        "    Kg = {'Infant':np.zeros(n), 'Child':np.zeros(n), 'Adult':np.zeros(n)}\n",
        "    for age in INFANT+CHILD+ADULT:\n",
        "        act=sample_AcTout(age, n)  # /1440 없음\n",
        "        add = act * EF * (ED_years[age]/LT_years) * ADAF(age)\n",
        "        if age in INFANT: Kg['Infant'] += add\n",
        "        elif age in CHILD: Kg['Child'] += add\n",
        "        else: Kg['Adult'] += add\n",
        "    Kg['Lifetime'] = Kg['Infant'] + Kg['Child'] + Kg['Adult']\n",
        "    return Kg\n",
        "\n",
        "Kg = K_by_group(N_SIM)\n",
        "\n",
        "# 대표 금속농도 난수: 각 금속 최선분포 기반; Cr(VI)=Cr/7\n",
        "C_sims={}\n",
        "for m in ORDER:\n",
        "    if m=='Cr(VI)':\n",
        "        if 'Cr' in C_sims: C_sims[m]=C_sims['Cr']/7.0\n",
        "        continue\n",
        "    if m not in trimmed or trimmed[m].size==0: continue\n",
        "    info=fit_tables[m]['best']\n",
        "    if info is None:\n",
        "        x=trimmed[m].values\n",
        "        idx=np.random.randint(0,len(x),size=N_SIM); C_sims[m]=x[idx]\n",
        "    else:\n",
        "        dist=info['obj']; C_sims[m]=dist.rvs(N_SIM, rs=child_rs())\n",
        "if 'Cr(VI)' not in C_sims and 'Cr' in C_sims:\n",
        "    C_sims['Cr(VI)']=C_sims['Cr']/7.0\n",
        "\n",
        "# Build workbook\n",
        "wb=Workbook()\n",
        "\n",
        "# 1) Tx-적합도 보고서\n",
        "ws=wb.active; ws.title=\"Tx-적합도 보고서\"\n",
        "def set_col_widths(ws, widths):\n",
        "    for col,w in widths.items(): ws.column_dimensions[col].width = w\n",
        "def styled_header(ws, row, headers, start_col=1, fill_color=HEADER_BLUE):\n",
        "    fill = PatternFill('solid', fgColor=fill_color)\n",
        "    white = Font(color='FFFFFF', bold=True)\n",
        "    center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
        "    thin = Border(left=Side(style='thin', color=THIN_GRAY),\n",
        "                  right=Side(style='thin', color=THIN_GRAY),\n",
        "                  top=Side(style='thin', color=THIN_GRAY),\n",
        "                  bottom=Side(style='thin', color=THIN_GRAY))\n",
        "    for j,h in enumerate(headers, start=start_col):\n",
        "        c = ws.cell(row=row, column=j, value=h)\n",
        "        c.fill = fill; c.font = white; c.alignment = center; c.border = thin\n",
        "def write_num(ws, r, c, v, fmt='0.0000'):\n",
        "    cell = ws.cell(row=r, column=c)\n",
        "    if v is None or (isinstance(v,float) and (np.isnan(v) or np.isinf(v))):\n",
        "        cell.value = '---'\n",
        "    else:\n",
        "        cell.value = float(v) if isinstance(v,(int,float,np.floating)) else v\n",
        "        if isinstance(v,(int,float,np.floating)): cell.number_format = fmt\n",
        "def highlight_best_row(ws, start_row, nrows, start_col=1, end_col=8):\n",
        "    if nrows<=0: return\n",
        "    fill = PatternFill('solid', fgColor=BEST_FILL)\n",
        "    r = start_row + 1\n",
        "    for c in range(start_col, end_col+1): ws.cell(row=r, column=c).fill = fill\n",
        "\n",
        "set_col_widths(ws, {'A':18,'B':12,'C':10,'D':10,'E':10,'F':10,'G':12,'H':12,'I':64})\n",
        "ws.freeze_panes = 'B3'\n",
        "ws['A1'] = '순위 지정 기준: 앤더슨-달링 → KS p → χ² p → 모수 수'\n",
        "ws['A2'] = '데이터 계열'\n",
        "\n",
        "row = 3; table_idx = 1\n",
        "for m in ORDER:\n",
        "    ws.cell(row=row, column=1, value=m).font = Font(bold=True); row += 1\n",
        "    headers = ['분포','A-D','A-D P-값','K-S','K-S P-값','카이제곱','카이제곱 P-값','매개 변수']\n",
        "    styled_header(ws, row, headers, start_col=2)\n",
        "    start_row = row; row += 1\n",
        "\n",
        "    tbl = fit_tables.get(m, {}).get('table', pd.DataFrame())\n",
        "    if tbl is None or tbl.empty:\n",
        "        note = \"(No sample)\" if (m not in trimmed or trimmed[m].size==0) else \\\n",
        "               (\"Cr(VI) uses Cr’s fitted distribution scaled by 1/7\" if m=='Cr(VI)' else \"(No table)\")\n",
        "        ws.cell(row=row, column=2, value=note); row += 2\n",
        "        continue\n",
        "\n",
        "    for i, r_ in tbl.iterrows():\n",
        "        rr = row + i\n",
        "        ws.cell(row=rr, column=2, value=r_['분포'])\n",
        "        write_num(ws, rr,3, r_['AD'])\n",
        "        write_num(ws, rr,4, r_['ADp'])\n",
        "        write_num(ws, rr,5, r_['KSp'])\n",
        "        write_num(ws, rr,6, r_['Chi2p'])\n",
        "        write_num(ws, rr,7, r_['np'], fmt='0')\n",
        "        param_text = pstr(r_['분포'], (tbl.iloc[0]['obj'].p if i==0 else r_['obj'].p))\n",
        "        ws.cell(row=rr, column=9, value=param_text)\n",
        "    end_row = row + len(tbl) - 1\n",
        "    try:\n",
        "        t = Table(displayName=f\"T_{table_idx}\", ref=f\"B{start_row}:I{end_row}\")\n",
        "        t.tableStyleInfo = TableStyleInfo(name=TABLE_STYLE, showFirstColumn=False, showLastColumn=False,\n",
        "                                          showRowStripes=True, showColumnStripes=False)\n",
        "        ws.add_table(t); table_idx += 1\n",
        "    except Exception: pass\n",
        "    highlight_best_row(ws, start_row, len(tbl), start_col=2, end_col=9)\n",
        "    row = end_row + 2\n",
        "\n",
        "# 2) Tx-일괄 분포 적합 가정\n",
        "ws2 = wb.create_sheet(\"Tx-일괄 분포 적합 가정\")\n",
        "all_cols = ORDER[:]\n",
        "set_col_widths(ws2, {'A':22, **{chr(66+i):12 for i in range(len(all_cols))}})\n",
        "ws2.freeze_panes = 'B2'\n",
        "GREEN = '00B050'\n",
        "def styled_header2(ws, row, headers): styled_header(ws, row, headers, start_col=1, fill_color=GREEN)\n",
        "styled_header2(ws2, 1, ['데이터 계열'] + all_cols)\n",
        "\n",
        "labels = ['분포:', '최선 적합:', '앤더슨-달링:', 'P 값:', '선택 범위(5–95%):', '5%:', '95%:']\n",
        "for i, lab in enumerate(labels, start=2):\n",
        "    ws2.cell(row=i, column=1, value=lab).font = Font(bold=True)\n",
        "\n",
        "def fill_best_cells(j, src_m):\n",
        "    tbl = fit_tables.get(src_m, {}).get('table', pd.DataFrame())\n",
        "    if tbl is not None and not tbl.empty:\n",
        "        best = tbl.iloc[0]\n",
        "        ws2.cell(row=3, column=j, value=str(best['분포']))   # 최선 적합\n",
        "        write_num(ws2, 4, j, best['AD'], fmt='0.0000')       # A-D\n",
        "        write_num(ws2, 5, j, best['ADp'], fmt='0.000')       # P 값\n",
        "    else:\n",
        "        ws2.cell(row=3, column=j, value='표본부족')\n",
        "        ws2.cell(row=4, column=j, value='---')\n",
        "        ws2.cell(row=5, column=j, value='---')\n",
        "\n",
        "for j, m in enumerate(all_cols, start=2):\n",
        "    # 분포: = 모드\n",
        "    if m=='Cr(VI)' and 'Cr' in mode_map:\n",
        "        write_num(ws2, 2, j, mode_map['Cr']/7.0, fmt='0.0000')\n",
        "    else:\n",
        "        write_num(ws2, 2, j, mode_map.get(m, None), fmt='0.0000')\n",
        "\n",
        "    # 최선 적합/검정: Cr(VI)는 Cr 복사, 그 외는 자체\n",
        "    if m=='Cr(VI)' and 'Cr' in fit_tables and (fit_tables['Cr']['table'] is not None) and (not fit_tables['Cr']['table'].empty):\n",
        "        fill_best_cells(j, 'Cr')\n",
        "    else:\n",
        "        fill_best_cells(j, m)\n",
        "\n",
        "    # 선택 범위 + 5%/95%\n",
        "    if m=='Cr(VI)' and 'Cr' in q5_map and 'Cr' in q95_map:\n",
        "        lo,hi = q5_map['Cr']/7.0, q95_map['Cr']/7.0\n",
        "        ws2.cell(row=6, column=j, value=f\"{lo:.4f} ~ {hi:.4f}\")\n",
        "        write_num(ws2, 7, j, lo, fmt='0.0000')\n",
        "        write_num(ws2, 8, j, hi, fmt='0.0000')\n",
        "    else:\n",
        "        lo,hi = q5_map.get(m, None), q95_map.get(m, None)\n",
        "        if (lo is None) or (hi is None) or (not np.isfinite(lo)) or (not np.isfinite(hi)):\n",
        "            ws2.cell(row=6, column=j, value=\"---\")\n",
        "            ws2.cell(row=7, column=j, value=\"---\")\n",
        "            ws2.cell(row=8, column=j, value=\"---\")\n",
        "        else:\n",
        "            ws2.cell(row=6, column=j, value=f\"{lo:.4f} ~ {hi:.4f}\")\n",
        "            write_num(ws2, 7, j, lo, fmt='0.0000')\n",
        "            write_num(ws2, 8, j, hi, fmt='0.0000')\n",
        "\n",
        "# 저장 및 다운\n",
        "OUT=\"Tx.xlsx\"\n",
        "wb.save(OUT)\n",
        "print(\"Saved:\", OUT)\n",
        "files.download(OUT)\n",
        "files.download(\"preprocessed/preprocessed_data.xlsx\")\n",
        "files.download(\"preprocessed/preprocess_log.xlsx\")\n",
        "\n",
        "# 코랩에 결과값 출력: LADD/LECR (Infant/Child/Adult/Lifetime)\n",
        "# 금속별 LADD/LECR 요약 + Cumulative LECR\n",
        "def summarize_risk(C_sims, Kg):\n",
        "    # 그룹별 K 합 (벡터) -> LADD/LECR 통계\n",
        "    out_rows=[]\n",
        "    cum_vec = np.zeros(N_SIM)\n",
        "    for m in ORDER:\n",
        "        if (m not in IUR) or (m not in C_sims): continue\n",
        "        C = C_sims[m]\n",
        "        ladd_inf = C * Kg['Infant']\n",
        "        ladd_ch  = C * Kg['Child']\n",
        "        ladd_ad  = C * Kg['Adult']\n",
        "        ladd_tot = C * Kg['Lifetime']\n",
        "        # LECR\n",
        "        iur = IUR[m]\n",
        "        lecr_inf = ladd_inf * iur\n",
        "        lecr_ch  = ladd_ch  * iur\n",
        "        lecr_ad  = ladd_ad  * iur\n",
        "        lecr_tot = ladd_tot * iur\n",
        "        cum_vec += lecr_tot\n",
        "\n",
        "        def stats1(v):\n",
        "            return dict(mean=float(np.mean(v)), median=float(np.median(v)),\n",
        "                        p95=float(np.percentile(v,95)), p99=float(np.percentile(v,99)))\n",
        "\n",
        "        out_rows.append({\n",
        "            'Metal': m,\n",
        "            'LADD_Infant': stats1(ladd_inf),\n",
        "            'LADD_Child' : stats1(ladd_ch),\n",
        "            'LADD_Adult' : stats1(ladd_ad),\n",
        "            'LADD_Lifetime': stats1(ladd_tot),\n",
        "            'LECR_Infant': stats1(lecr_inf),\n",
        "            'LECR_Child' : stats1(lecr_ch),\n",
        "            'LECR_Adult' : stats1(lecr_ad),\n",
        "            'LECR_Lifetime': stats1(lecr_tot),\n",
        "        })\n",
        "\n",
        "    cum_stats = {'Cumulative_LECR_Lifetime': {\n",
        "        'mean': float(np.mean(cum_vec)),\n",
        "        'median': float(np.median(cum_vec)),\n",
        "        'p95': float(np.percentile(cum_vec,95)),\n",
        "        'p99': float(np.percentile(cum_vec,99)),\n",
        "    }}\n",
        "    return out_rows, cum_stats\n",
        "\n",
        "risk_rows, cum_stats = summarize_risk(C_sims, Kg)\n",
        "\n",
        "# 최종 결과값 출력\n",
        "def fmt_stats(d):\n",
        "    return f\"mean={d['mean']:.6g}, median={d['median']:.6g}, P95={d['p95']:.6g}, P99={d['p99']:.6g}\"\n",
        "\n",
        "print(\"\\n===== LADD / LECR 요약 (Infant / Child / Adult / Lifetime, per Metal) =====\")\n",
        "for r in risk_rows:\n",
        "    m = r['Metal']\n",
        "    print(f\"\\n[{m}]\")\n",
        "    print(\"  LADD_Infant  :\", fmt_stats(r['LADD_Infant']))\n",
        "    print(\"  LADD_Child   :\", fmt_stats(r['LADD_Child']))\n",
        "    print(\"  LADD_Adult   :\", fmt_stats(r['LADD_Adult']))\n",
        "    print(\"  LADD_Lifetime:\", fmt_stats(r['LADD_Lifetime']))\n",
        "    print(\"  LECR_Infant  :\", fmt_stats(r['LECR_Infant']))\n",
        "    print(\"  LECR_Child   :\", fmt_stats(r['LECR_Child']))\n",
        "    print(\"  LECR_Adult   :\", fmt_stats(r['LECR_Adult']))\n",
        "    print(\"  LECR_Lifetime:\", fmt_stats(r['LECR_Lifetime']))\n",
        "\n",
        "print(\"\\n===== Cumulative LECR (Lifetime, across metals with IUR) =====\")\n",
        "cs = cum_stats['Cumulative_LECR_Lifetime']\n",
        "print(f\"  mean={cs['mean']:.6g}, median={cs['median']:.6g}, P95={cs['p95']:.6g}, P99={cs['p99']:.6g}\")\n"
      ],
      "metadata": {
        "id": "NeZeQPkS4s3w",
        "outputId": "c6996d08-3272-4e80-e8ea-5dcc86e53f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "로우데이터 엑셀 업로드(.xlsx)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-375243cc-76cb-43ec-adbb-859aa21ae283\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-375243cc-76cb-43ec-adbb-859aa21ae283\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 202501_clean2.xlsx to 202501_clean2 (9).xlsx\n",
            "Saved: Tx.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6c7b160b-b670-4f89-89ec-dc8fc483e1aa\", \"Tx.xlsx\", 17103)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4a9eeb5e-a817-4164-b6ef-36dd0e38c895\", \"preprocessed_data.xlsx\", 44364)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f6e2e4a9-d7e9-41fd-9fbb-4e36a46e28c2\", \"preprocess_log.xlsx\", 5310)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== LADD / LECR 요약 (Infant / Child / Adult / Lifetime, per Metal) =====\n",
            "\n",
            "[Cr(VI)]\n",
            "  LADD_Infant  : mean=0.00738951, median=0.0073755, P95=0.0130688, P99=0.0155039\n",
            "  LADD_Child   : mean=0.0240467, median=0.0240011, P95=0.042528, P99=0.0504522\n",
            "  LADD_Adult   : mean=0.0263947, median=0.0205614, P95=0.0676292, P99=0.112441\n",
            "  LADD_Lifetime: mean=0.0578309, median=0.0539121, P95=0.115819, P99=0.162687\n",
            "  LECR_Infant  : mean=8.86741e-05, median=8.8506e-05, P95=0.000156826, P99=0.000186047\n",
            "  LECR_Child   : mean=0.00028856, median=0.000288013, P95=0.000510336, P99=0.000605426\n",
            "  LECR_Adult   : mean=0.000316736, median=0.000246736, P95=0.00081155, P99=0.00134929\n",
            "  LECR_Lifetime: mean=0.000693971, median=0.000646945, P95=0.00138982, P99=0.00195225\n",
            "\n",
            "[Co]\n",
            "  LADD_Infant  : mean=0.13502, median=0.131611, P95=0.234327, P99=0.276387\n",
            "  LADD_Child   : mean=0.439376, median=0.428286, P95=0.762541, P99=0.89941\n",
            "  LADD_Adult   : mean=0.481248, median=0.371352, P95=1.2186, P99=1.93507\n",
            "  LADD_Lifetime: mean=1.05564, median=0.969799, P95=2.04861, P99=2.84019\n",
            "  LECR_Infant  : mean=0.00121518, median=0.0011845, P95=0.00210895, P99=0.00248748\n",
            "  LECR_Child   : mean=0.00395438, median=0.00385457, P95=0.00686287, P99=0.00809469\n",
            "  LECR_Adult   : mean=0.00433123, median=0.00334216, P95=0.0109674, P99=0.0174156\n",
            "  LECR_Lifetime: mean=0.00950079, median=0.00872819, P95=0.0184374, P99=0.0255617\n",
            "\n",
            "[Ni]\n",
            "  LADD_Infant  : mean=0.0510183, median=0.047988, P95=0.0995159, P99=0.124415\n",
            "  LADD_Child   : mean=0.166022, median=0.156161, P95=0.323841, P99=0.404867\n",
            "  LADD_Adult   : mean=0.181504, median=0.136507, P95=0.481494, P99=0.800275\n",
            "  LADD_Lifetime: mean=0.398544, median=0.352852, P95=0.846278, P99=1.22282\n",
            "  LECR_Infant  : mean=1.22444e-05, median=1.15171e-05, P95=2.38838e-05, P99=2.98596e-05\n",
            "  LECR_Child   : mean=3.98453e-05, median=3.74786e-05, P95=7.77219e-05, P99=9.7168e-05\n",
            "  LECR_Adult   : mean=4.3561e-05, median=3.27616e-05, P95=0.000115559, P99=0.000192066\n",
            "  LECR_Lifetime: mean=9.56506e-05, median=8.46846e-05, P95=0.000203107, P99=0.000293476\n",
            "\n",
            "[Cd]\n",
            "  LADD_Infant  : mean=3.75237, median=3.66653, P95=5.0843, P99=5.25334\n",
            "  LADD_Child   : mean=12.2108, median=11.9315, P95=16.5451, P99=17.0953\n",
            "  LADD_Adult   : mean=13.3714, median=10.8393, P95=30.68, P99=49.1569\n",
            "  LADD_Lifetime: mean=29.3346, median=27.2749, P95=48.8967, P99=68.0536\n",
            "  LECR_Infant  : mean=0.00675426, median=0.00659976, P95=0.00915173, P99=0.00945602\n",
            "  LECR_Child   : mean=0.0219795, median=0.0214767, P95=0.0297813, P99=0.0307715\n",
            "  LECR_Adult   : mean=0.0240685, median=0.0195107, P95=0.055224, P99=0.0884824\n",
            "  LECR_Lifetime: mean=0.0528022, median=0.0490948, P95=0.0880141, P99=0.122497\n",
            "\n",
            "[Sb]\n",
            "  LADD_Infant  : mean=0.297754, median=0.266026, P95=0.663616, P99=0.717559\n",
            "  LADD_Child   : mean=0.968942, median=0.865693, P95=2.15952, P99=2.33506\n",
            "  LADD_Adult   : mean=1.06091, median=0.743328, P95=3.09325, P99=5.29471\n",
            "  LADD_Lifetime: mean=2.32761, median=1.95393, P95=5.51489, P99=7.89446\n",
            "  LECR_Infant  : mean=6.81858e-07, median=6.09199e-07, P95=1.51968e-06, P99=1.64321e-06\n",
            "  LECR_Child   : mean=2.21888e-06, median=1.98244e-06, P95=4.94529e-06, P99=5.34728e-06\n",
            "  LECR_Adult   : mean=2.42949e-06, median=1.70222e-06, P95=7.08355e-06, P99=1.21249e-05\n",
            "  LECR_Lifetime: mean=5.33022e-06, median=4.4745e-06, P95=1.26291e-05, P99=1.80783e-05\n",
            "\n",
            "[Pb]\n",
            "  LADD_Infant  : mean=0.147136, median=0.11376, P95=0.388517, P99=0.563795\n",
            "  LADD_Child   : mean=0.478806, median=0.370195, P95=1.2643, P99=1.83468\n",
            "  LADD_Adult   : mean=0.523873, median=0.332863, P95=1.63748, P99=2.99277\n",
            "  LADD_Lifetime: mean=1.14982, median=0.855374, P95=3.17385, P99=4.8712\n",
            "  LECR_Infant  : mean=1.76563e-06, median=1.36512e-06, P95=4.6622e-06, P99=6.76553e-06\n",
            "  LECR_Child   : mean=5.74567e-06, median=4.44234e-06, P95=1.51716e-05, P99=2.20162e-05\n",
            "  LECR_Adult   : mean=6.28648e-06, median=3.99436e-06, P95=1.96498e-05, P99=3.59133e-05\n",
            "  LECR_Lifetime: mean=1.37978e-05, median=1.02645e-05, P95=3.80862e-05, P99=5.84544e-05\n",
            "\n",
            "===== Cumulative LECR (Lifetime, across metals with IUR) =====\n",
            "  mean=0.0631118, median=0.0585066, P95=0.103724, P99=0.144557\n"
          ]
        }
      ]
    }
  ]
}